{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52090cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011a80e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "train = train.iloc[:2000, ]\n",
    "test = test.iloc[:1000, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55515a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "train_word_lengths = [len(nltk_tokenizer.tokenize(review)) for review in train.review]\n",
    "test_word_lengths = [len(nltk_tokenizer.tokenize(review)) for review in test.review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f8b41d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min train word length: 18\n",
      "Max train word length: 1532\n",
      "Average train word length: 230.419\n",
      "SD train word length: 166.7656662475823\n",
      "Total positive reviews in train: 1005\n",
      "\n",
      "Min test word length: 25\n",
      "Max test word length: 1020\n",
      "Average test word length: 240.918\n",
      "SD test word length: 173.3413143944628\n",
      "Total positive reviews in test: 541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min train word length: {min(train_word_lengths)}\")\n",
    "print(f\"Max train word length: {max(train_word_lengths)}\")\n",
    "print(f\"Average train word length: {np.mean(train_word_lengths)}\")\n",
    "print(f\"SD train word length: {np.std(train_word_lengths)}\")\n",
    "print(f\"Total positive reviews in train: {sum(train.sentiment)}\\n\")\n",
    "print(f\"Min test word length: {min(test_word_lengths)}\")\n",
    "print(f\"Max test word length: {max(test_word_lengths)}\")\n",
    "print(f\"Average test word length: {np.mean(test_word_lengths)}\")\n",
    "print(f\"SD test word length: {np.std(test_word_lengths)}\")\n",
    "print(f\"Total positive reviews in test: {sum(test.sentiment)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6653b9c8",
   "metadata": {},
   "source": [
    "# BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16b9b035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\arthu/.cache\\torch\\hub\\huggingface_pytorch-transformers_main\n"
     ]
    }
   ],
   "source": [
    "# Load the vanilla BERT model and tokenizer\n",
    "bert_tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "459e0548",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert_lengths = [len(bert_tokenizer.tokenize(review)) for review in train.review]\n",
    "test_bert_lengths = [len(bert_tokenizer.tokenize(review)) for review in test.review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d4f03ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min train token length: 24\n",
      "Max train token length: 1797\n",
      "Average train token length: 285.595\n",
      "SD train token length: 208.33075139066725\n",
      "Min test token length: 35\n",
      "Max test token length: 1323\n",
      "Average test token length: 298.738\n",
      "SD test token length: 214.59573005071653\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min train token length: {min(train_bert_lengths)}\")\n",
    "print(f\"Max train token length: {max(train_bert_lengths)}\")\n",
    "print(f\"Average train token length: {np.mean(train_bert_lengths)}\")\n",
    "print(f\"SD train token length: {np.std(train_bert_lengths)}\")\n",
    "print(f\"Min test token length: {min(test_bert_lengths)}\")\n",
    "print(f\"Max test token length: {max(test_bert_lengths)}\")\n",
    "print(f\"Average test token length: {np.mean(test_bert_lengths)}\")\n",
    "print(f\"SD test token length: {np.std(test_bert_lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25888cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train reviews longer than 512 tokens: 240\n",
      "Test reviews longer than 512 tokens: 133\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train reviews longer than 512 tokens: {sum([length > 512 for length in train_bert_lengths])}\")\n",
    "print(f\"Test reviews longer than 512 tokens: {sum([length > 512 for length in test_bert_lengths])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5ea4a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test lengths that get put into BERT, truncated to 512 tokens\n",
    "trunc_train_bert_lengths = [512 if length > 512 else length for length in train_bert_lengths]\n",
    "trunc_test_bert_lengths = [512 if length > 512 else length for length in test_bert_lengths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "908d092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min train token length: 24\n",
      "Max train token length: 512\n",
      "Average train token length: 258.726\n",
      "SD train token length: 136.72124898493286\n",
      "Min test token length: 35\n",
      "Max test token length: 512\n",
      "Average test token length: 267.811\n",
      "SD test token length: 139.32881711620178\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min train token length: {min(trunc_train_bert_lengths)}\")\n",
    "print(f\"Max train token length: {max(trunc_train_bert_lengths)}\")\n",
    "print(f\"Average train token length: {np.mean(trunc_train_bert_lengths)}\")\n",
    "print(f\"SD train token length: {np.std(trunc_train_bert_lengths)}\")\n",
    "print(f\"Min test token length: {min(trunc_test_bert_lengths)}\")\n",
    "print(f\"Max test token length: {max(trunc_test_bert_lengths)}\")\n",
    "print(f\"Average test token length: {np.mean(trunc_test_bert_lengths)}\")\n",
    "print(f\"SD test token length: {np.std(trunc_test_bert_lengths)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (STATS232)",
   "language": "python",
   "name": "stats232"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
